{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d619fa46",
   "metadata": {},
   "source": [
    "# Lab SGD\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba54921e",
   "metadata": {},
   "source": [
    "Learning setup based on a [PyTorch tutorial](https://docs.pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0adf1754",
   "metadata": {},
   "source": [
    "## Boilerplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e87350c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "data_path = \"./data\"\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device(\"cuda\")\n",
    "elif torch.mps.is_available():\n",
    "    DEVICE = torch.device(\"mps\")\n",
    "else:\n",
    "    DEVICE = torch.device(\"cpu\")\n",
    "\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735dbc3b",
   "metadata": {},
   "source": [
    "## Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c892b79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "trainset = datasets.CIFAR10(\n",
    "    root=\"./data\", train=True,\n",
    "    download=True, transform=transform)\n",
    "TRAINLOADER = DataLoader(\n",
    "    trainset, batch_size=batch_size,\n",
    "    shuffle=True, num_workers=4,\n",
    "    pin_memory=True)\n",
    "\n",
    "testset = datasets.CIFAR10(\n",
    "    root=\"./data\", train=False,\n",
    "    download=True, transform=transform)\n",
    "TESTLOADER = DataLoader(\n",
    "    testset, batch_size=batch_size,\n",
    "    shuffle=False, num_workers=4,\n",
    "    pin_memory=True)\n",
    "\n",
    "classes = (\"plane\", \"car\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2d9d6d",
   "metadata": {},
   "source": [
    "## Declare Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76693581",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.leaky_relu(self.conv1(x)))\n",
    "        x = self.pool(F.leaky_relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.leaky_relu(self.fc1(x))\n",
    "        x = F.leaky_relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3610a1",
   "metadata": {},
   "source": [
    "## Check Examples & Test Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d171b859",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _imshow(img: torch.Tensor) -> None:\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy(force=True)\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def check_examples(net: Net, testloader: DataLoader, n_examples=4) -> None:\n",
    "    net.eval()\n",
    "    dataiter = iter(testloader)\n",
    "    inputs, labels = next(dataiter)\n",
    "    inputs, labels = inputs[:n_examples].to(DEVICE), labels[:n_examples].to(DEVICE)\n",
    "\n",
    "    # print images\n",
    "    _imshow(make_grid(inputs))\n",
    "    print(\"GroundTruth: \", ' '.join(f\"{classes[label]:5s}\" for label in labels))\n",
    "\n",
    "    outputs = net(inputs)\n",
    "    _, predictions = torch.max(outputs, 1)\n",
    "\n",
    "    print(\"Predicted: \", ' '.join(f\"{classes[prediction]:5s}\" for prediction in predictions))\n",
    "\n",
    "\n",
    "def test_network(net: Net, testloader: DataLoader) -> None:\n",
    "    net.eval()\n",
    "    # prepare to count predictions for each class\n",
    "    correct_pred = {classname: 0 for classname in classes}\n",
    "    total_pred = {classname: 0 for classname in classes}\n",
    "\n",
    "    # again no gradients needed\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            images = images.to(DEVICE)\n",
    "            labels = labels.tolist()\n",
    "            outputs = net(images)\n",
    "            _, predictions = torch.max(outputs, 1)\n",
    "            predictions = predictions.tolist()\n",
    "            # collect the correct predictions for each class\n",
    "            for label, prediction in zip(labels, predictions):\n",
    "                if label == prediction:\n",
    "                    correct_pred[classes[label]] += 1\n",
    "                total_pred[classes[label]] += 1\n",
    "\n",
    "    # print accuracy for each class\n",
    "    for classname, correct_count in correct_pred.items():\n",
    "        accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "        print(f\"Accuracy for class: {classname:5s} is {accuracy:.1f} %\")\n",
    "\n",
    "    correct = sum(correct_pred.values())\n",
    "    total = sum(total_pred.values())\n",
    "    print(f\"Accuracy of the network on the 10000 test images: {100 * correct // total} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b1d704",
   "metadata": {},
   "source": [
    "## Manual training with basic SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f32285",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_sgd_manual(net: Net, n_epochs: int, lr: float) -> None:\n",
    "    net.train()\n",
    "    params = list(net.parameters())\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for data in TRAINLOADER:\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = net(inputs)\n",
    "            loss = F.cross_entropy(outputs, labels)\n",
    "\n",
    "            grads = torch.autograd.grad(loss, params)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for param, grad in zip(params, grads):\n",
    "                    param -= lr * grad\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        print(f\"epoch {epoch + 1:2d} loss: {running_loss / 2000:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4e3023",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(26)\n",
    "net = Net().to(DEVICE)\n",
    "train_sgd_manual(net, n_epochs=20, lr=1.0)\n",
    "test_network(net, TESTLOADER)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ddbba7",
   "metadata": {},
   "source": [
    "**Above learning rate is too high, leading to invalid loss values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881be9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(26)\n",
    "net = Net().to(DEVICE)\n",
    "train_sgd_manual(net, n_epochs=20, lr=0.001)\n",
    "test_network(net, TESTLOADER)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6765c11c",
   "metadata": {},
   "source": [
    "**Above learning rate is quite low, leading to little learning progress**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d65538",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(26)\n",
    "net = Net().to(DEVICE)\n",
    "train_sgd_manual(net, n_epochs=20, lr=0.01)\n",
    "test_network(net, TESTLOADER)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84e4122",
   "metadata": {},
   "source": [
    "## Manual training with added momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c38301",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_momentum_manual(\n",
    "        net: Net, n_epochs: int, lr: float, momentum: float) -> None:\n",
    "    net.train()\n",
    "    params = list(net.parameters())\n",
    "\n",
    "    velocities = [torch.zeros_like(p) for p in params]\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for data in TRAINLOADER:\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = net(inputs)\n",
    "            loss = F.cross_entropy(outputs, labels)\n",
    "\n",
    "            grads = torch.autograd.grad(loss, params)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for param, grad, velocity in zip(params, grads, velocities):\n",
    "                    velocity.mul_(momentum).add_(grad)\n",
    "                    param -= lr * velocity\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        print(f\"epoch {epoch + 1:2d} loss: {running_loss / 2000:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0612b65",
   "metadata": {},
   "source": [
    "**When using momentum a lower base learning rate may be needed, but in this case we can keep it equal, allowing to see the change just from momentum**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc32327",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(26)\n",
    "net = Net().to(DEVICE)\n",
    "train_momentum_manual(net, n_epochs=20, lr=0.01, momentum=0.9)\n",
    "check_examples(net, TESTLOADER)\n",
    "#\n",
    "test_network(net, TESTLOADER)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f2b813",
   "metadata": {},
   "source": [
    "## Standard training with a torch optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2a3d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_opt(\n",
    "        net: Net, n_epochs: int, optimizer: torch.optim.Optimizer) -> None:\n",
    "    net.train()\n",
    "\n",
    "    for epoch in range(n_epochs):  # loop over the dataset multiple times\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for data in TRAINLOADER:\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = F.cross_entropy(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        print(f\"epoch {epoch + 1:2d} loss: {running_loss / 2000:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758c8f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(26)\n",
    "net = Net().to(DEVICE)\n",
    "train_opt(net, 20, torch.optim.SGD(net.parameters(), lr=0.01))\n",
    "test_network(net, TESTLOADER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f331daf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(26)\n",
    "net = Net().to(DEVICE)\n",
    "train_opt(net, 20, torch.optim.SGD(net.parameters(), lr=0.01, momentum=0.9))\n",
    "test_network(net, TESTLOADER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abdf3224",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(26)\n",
    "net = Net().to(DEVICE)\n",
    "train_opt(net, 20, torch.optim.AdamW(net.parameters(), lr=0.001))\n",
    "test_network(net, TESTLOADER)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966562e9",
   "metadata": {},
   "source": [
    "**AdamW needs a lower learning rate than SGD with momentum, but also gets a better loss (and slightly better accuracy)**\n",
    "\n",
    "**AdamW often has a stronger advantage also in testing for other (more complex) network types**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16609aa8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
