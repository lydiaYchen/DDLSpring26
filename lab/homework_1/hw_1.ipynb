{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For part A, fill in the code and answers within the notebook and save your changes.\n",
    "\n",
    "For part B, create and archive the necessary Python/shell scripts together.\n",
    "\n",
    "Finally, upload the notebook and the archive to the assignment in ILIAS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part A (12 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part of the homework uses automatic tests for grading correctness.\n",
    "\n",
    "Please do not delete tagged notebook cells or rename already declared funcs/classes.\n",
    "\n",
    "The tests are split into a public and a private set.\n",
    "\n",
    "To see how your solution does on the public set:\n",
    "- ensure your working dir is that of the homework and the lab env is active;\n",
    "- run `pytest -fpath PATH_TO_YOUR_NOTEBOOK`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "setup"
    ]
   },
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "import pandas as pd\n",
    "from lab_2_hfl.hfl_complete import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When not otherwise specified, you can use the following default parameter values to test your code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100\n",
    "iid = True\n",
    "seed = 10\n",
    "lr = 0.01\n",
    "c = 0.1         # client fraction\n",
    "b = 100         # batch_size\n",
    "e = 1           # nr_local_epochs\n",
    "nr_rounds = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise A1: FedSGD and FedAvg variants (3 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_(1 point)_ Implement a version of FedSGD that uses weights in its updates, like FedAvg, instead of the gradients from the version of the tutorials.\n",
    "\n",
    "*Tip:* You can use the existing FedAvg implementation to minimize the amount of code writing required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "fedsgd_weight"
    ]
   },
   "outputs": [],
   "source": [
    "class FedSgdWeightServer(FedAvgServer):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_(1 point)_ Explain in which cases (for the different decentralized data learning parameters) weight and gradient FedSGD are equivalent.\n",
    "\n",
    "Give an example batch size and an example number of local epochs for which gradient and weight FEDSGD are not equivalent.\n",
    "\n",
    "You may assume the maximum possible data samples in a client is 600."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "fedsgd_diff"
    ]
   },
   "outputs": [],
   "source": [
    "fed_sgd_grad_unequal_weight_bs = ...\n",
    "\n",
    "fed_sgd_grad_unequal_weight_e = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_(1 point)_ Implement a version of FedAvg that uses pseudo-gradients in its updates instead of weights.\n",
    "\n",
    "Pseudo-gradients should be the difference between old and new weights.\n",
    "\n",
    "Keep `PseudoGradClient` inside `FedAvgGradServer` and refer to it via `FedAvgGradServer.PseudoGradClient`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "fedavg_grad"
    ]
   },
   "outputs": [],
   "source": [
    "class FedAvgGradServer(DecentralizedServer):\n",
    "    class PseudoGradClient(Client):\n",
    "        ...\n",
    "\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise A2: Client number & fraction (4 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_(2 points)_ The table below shows the final message count and test accuracy of FedSGD and FedAvg for different total client numbers.\n",
    "\n",
    "Complete the definition of `client_number_experiments` to run the necessary experiments for filling out the table and return it as a DataFrame.\n",
    "\n",
    "Then, answer the multiple-choice questions in `ClientNumberObservations` by assigning one of the indicated possible values to each class variable.\n",
    "\n",
    "| Algorithm | N   | C   | Message count | Test accuracy |\n",
    "| --------- | --- | --- | ------------- | ------------- |\n",
    "| FedSGD    | 10  | 0.1 |               |               |\n",
    "| FedAvg    | 10  | 0.1 |               |               |\n",
    "| FedSGD    | 50  | 0.1 |               |               |\n",
    "| FedAvg    | 50  | 0.1 |               |               |\n",
    "| FedSGD    | 100 | 0.1 |               |               |\n",
    "| FedAvg    | 100 | 0.1 |               |               |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "client_number_experiments"
    ]
   },
   "outputs": [],
   "source": [
    "def client_number_experiments(\n",
    "        iid=True, seed=10, lr=0.01, c=0.1,\n",
    "        b=100, e=1, nr_rounds=10) -> pd.DataFrame:\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "client_number_observations"
    ]
   },
   "outputs": [],
   "source": [
    "class ClientNumberObservations:\n",
    "    \"Q1: Which method has higher message counts (given equal N and C)?\"\n",
    "    q1: Literal[\"fedsgd\", \"fedavg\", \"neither\"] = ...\n",
    "    \"Q2: Which method's accuracy is more affected by increasing N?\"\n",
    "    q2: Literal[\"fedsgd\", \"fedavg\"] = ...\n",
    "    \"Q3: Does increasing N tend to have a negative or positive accuracy impact?\"\n",
    "    q3: Literal[\"negative\", \"positive\"] = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_(2 points)_ Below is a similar table for varying the fraction of clients used in every round.\n",
    "\n",
    "Similarly to the previous question, complete the definition of `client_fraction_experiments`,\n",
    "then answer the multiple-choice questions in `ClientFractionObservations`.\n",
    "\n",
    "| Algorithm | N   | C    | Message count | Test accuracy |\n",
    "| --------- | --- | ---- | ------------- | ------------- |\n",
    "| FedSGD    | 100 | 0.01 |               |               |\n",
    "| FedAvg    | 100 | 0.01 |               |               |\n",
    "| FedSGD    | 100 | 0.1  |               |               |\n",
    "| FedAvg    | 100 | 0.1  |               |               |\n",
    "| FedSGD    | 100 | 0.2  |               |               |\n",
    "| FedAvg    | 100 | 0.2  |               |               |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "client_fraction_experiments"
    ]
   },
   "outputs": [],
   "source": [
    "def client_fraction_experiments(\n",
    "        n=100, iid=True, seed=10, lr=0.01,\n",
    "        b=100, e=1, nr_rounds=10) -> pd.DataFrame:\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "client_fraction_observations"
    ]
   },
   "outputs": [],
   "source": [
    "class ClientFractionObservations:\n",
    "    \"Q1: Which method has the highest accuracy (given equal N and C)?\"\n",
    "    q1: Literal[\"fedsgd\", \"fedavg\"] = ...\n",
    "    \"Q2: How does increasing C impact the number of messages?\"\n",
    "    q2: Literal[\"increase\", \"decrease\", \"neither\"] = ...\n",
    "    \"Q3: Which method benefits least from a higher C?\"\n",
    "    q3: Literal[\"fedsgd\", \"fedavg\"] = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise A3: Local epoch count & (non-)IID data (5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_(1 point)_ Consider the following algorithm variants:\n",
    "\n",
    "- `FedSGD E=1`\n",
    "- `FedAvg E=1`\n",
    "- `FedAvg E=2`\n",
    "- `FedAvg E=4`\n",
    "\n",
    "Complete the definition of `local_epoch_experiments` to run each of the variants above and return a dictionary with the accuracy after every round for each.\n",
    "\n",
    "The dictionary keys should match the entries in the list above.\n",
    "Then, answer the multiple-choice questions in `LocalEpochObservations`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "local_epoch_experiments"
    ]
   },
   "outputs": [],
   "source": [
    "def local_epoch_experiments(\n",
    "        n=100, iid=True, seed=10, lr=0.01,\n",
    "        b=100, c=0.1, nr_rounds=10) -> dict[str, list[float]]:\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "local_epoch_observations"
    ]
   },
   "outputs": [],
   "source": [
    "class LocalEpochObservations:\n",
    "    \"Q1: For E=1, which method has the highest accuracy?\"\n",
    "    q1: Literal[\"fedsgd\", \"fedavg\"] = ...\n",
    "    \"Q2: What is the effect of increasing E on accuracy?\"\n",
    "    q2: Literal[\"decrease\", \"increase\", \"depends\"] = ...\n",
    "    \"Q3: How does the effect on accuracy change as E increases?\"\n",
    "    q3: Literal[\"decrease\", \"increase\"] = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_(2 points)_ Consider the following scenarios:\n",
    "\n",
    "- `FedSGD iid`\n",
    "- `FedSGD non-iid`\n",
    "- `FedAvg iid`\n",
    "- `FedAvg non-iid`\n",
    "\n",
    "Similarly to the previous question, complete the definition of `iid_noniid_experiments`,\n",
    "then answer the multiple-choice questions in `IidNonIidObservations`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "iid_noniid_experiments"
    ]
   },
   "outputs": [],
   "source": [
    "def iid_noniid_experiments(\n",
    "        n=100, seed=10, lr=0.01,\n",
    "        b=100, c=0.1, e=1, nr_rounds=15) -> dict[str, list[float]]:\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "iid_noniid_observations"
    ]
   },
   "outputs": [],
   "source": [
    "class IidNonIidObservations:\n",
    "    \"Q1: In which case is learning easier?\"\n",
    "    q1: Literal[\"iid\", \"non-iid\"] = ...\n",
    "    \"Q2: Does accuracy tend to improve after each round in the non-iid case?\"\n",
    "    q2: bool = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_(2 points)_ Consider the following algorithm parameterizations **in the non-iid case**:\n",
    "\n",
    "- `FedSGD Old`\n",
    "- `FedSGD New`\n",
    "- `FedAvg Old`\n",
    "- `FedAvg New`\n",
    "\n",
    "For the `Old` case, use `lr=0.01` and `C=0.1`, as in the prior question.\n",
    "\n",
    "For the `New` case, use the lower `lr=0.001` and higher `C=0.5`.\n",
    "\n",
    "Similarly to the previous questions, complete the definition of `noniid_parameter_experiments`,\n",
    "then answer the multiple-choice questions in `NonIidParameterObservations`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "noniid_parameter_experiments"
    ]
   },
   "outputs": [],
   "source": [
    "def noniid_parameter_experiments(\n",
    "        n=100, seed=10,\n",
    "        b=100, e=1, nr_rounds=15) -> dict[str, list[float]]:\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "noniid_parameter_observations"
    ]
   },
   "outputs": [],
   "source": [
    "class NonIidParameterObservations:\n",
    "    \"Q1: How is the smoothness of learning in 'New' compared to 'Old'?\"\n",
    "    q1: Literal[\"worse\", \"better\", \"similar\"] = ...\n",
    "    \"Q2: Does 'New' significantly improve peak accuracy over 'Old'?\"\n",
    "    q2: bool = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part B (12 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise B1: Microbatch Pipeline Model Parallelism (7 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement pipeline parallelism with microbatches, as discussed during the lab.\n",
    "\n",
    "As with the other data/model parallelism examples, you will need a Python script for the nodes and a shell script to orchestrate execution.\n",
    "\n",
    "Be aware of the possibility of deadlocks: due to how `gloo` operates, it is possible to deadlock by having device 1 send $B_2$ to device 2 in the forward pass, and simultaneously, device 2 send $B_1$ in the backward pass.\n",
    "Since both sends will await corresponding receives, the training will stop indefinitely.\n",
    "\n",
    "Use `isend` & `irecv`, the asynchronous (non-blocking) versions of `send` & `recv` in `torch.distributed`.\n",
    "Each call of the two function returns a `Work` object, on which calling `wait()` blocks, if needed, until the message exchange finishes.\n",
    "Add comments or text explaining how you expect your implementation to work and test that it runs for the same number of steps and model architecture as in class.\n",
    "\n",
    "Note that `torch.distributed`'s implementation of `gloo` does not currently support properly asynchronous communication even when using the corresponding primitives.\n",
    "Thus, you will not see the same improvements in speed as with a backend like `nccl`.\n",
    "\n",
    "You may also use the fact that `torch` gradients naturally accumulate if not zeroed out.\n",
    "Also, scaling the loss by a constant is equivalent to scaling the resulting gradients by the same constant.\n",
    "\n",
    "You can rely on receiving messages in the same order they get sent between any device pair.\n",
    "The `(i)send/recv` functions all support a `tag` attribute to match messages explicitly.\n",
    "Although using it is good practice, it is not required.\n",
    "\n",
    "You can refer to the [documentation](https://pytorch.org/docs/stable/distributed.html) and, if helpful, a related [tutorial](https://brsoff.github.io/tutorials/intermediate/dist_tuto.html) on the PyTorch website."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise B2: Joint Data & Model Parallelism (5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement a training setup that uses data and model parallelism together.\n",
    "\n",
    "Create 2 pipelines of 3 stages running sequentially, where each stage works with 3 sequential micro-batches.\n",
    "\n",
    "Once again, add comments or text explaining your implementation and test it on the setting that mimics those from the class.\n",
    "\n",
    "You can use groups from `torch.distributed` to handle reduce operations between a subset of all workers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
